<!-- <!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Depth Map on Video</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/depth-estimation@2.0.0/dist/index.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js"></script>
    <style>
      body {
        margin: 0;
        display: flex;
        flex-direction: column;
        align-items: center;
        justify-content: center;
        background-color: black;
      }
      #video,
      #depthCanvas {
        position: absolute;
        top: 0;
        left: 0;
        width: 100%;
        height: auto;
      }
    </style>
  </head>
  <body>
    <video id="video" autoplay playsinline></video>
    <canvas id="depthCanvas"></canvas>

    <script>
      const video = document.getElementById("video");
      const depthCanvas = document.getElementById("depthCanvas");
      const depthCtx = depthCanvas.getContext("2d");
      let depthEstimator;
      async function toggleDepthMap() {
        if (depthCanvas.style.display === "none") {
          document.getElementById("toggleButton").innerText =
            "Скрыть карту глубины";
          depthCanvas.style.display = "block";
          if (!video) await startCamera();

          // Проверяем, загружена ли библиотека
          if (typeof depthEstimation !== "undefined") {
            if (!depthEstimator) await initializeDepthModel();
            updateDepthMap();
          } else {
            console.error(
              "depthEstimation не найден. Убедитесь, что библиотека правильно загружена.",
            );
          }
        } else {
          document.getElementById("toggleButton").innerText =
            "Показать карту глубины";
          depthCanvas.style.display = "none";
        }
      }
      // Запуск камеры
      async function startCamera() {
        const stream = await navigator.mediaDevices.getUserMedia({
          video: { facingMode: "environment" },
        });
        video.srcObject = stream;

        // Ожидаем загрузки видео
        video.onloadedmetadata = () => {
          video.play();
          depthCanvas.width = video.videoWidth;
          depthCanvas.height = video.videoHeight;
          initializeDepthModel();
        };
      }

      // Инициализация модели TensorFlow
      async function initializeDepthModel() {
        depthEstimator = await depthEstimation.createEstimator(
          depthEstimation.SupportedModels.COCODepthEstimation,
        );
        console.log("Depth model loaded");
        processVideo();
      }

      // Обработка видео и отрисовка карты глубины
      async function processVideo() {
        if (depthEstimator && video.readyState >= video.HAVE_ENOUGH_DATA) {
          // Генерация карты глубины
          const depthMap = await depthEstimator.estimateDepth(video);
          const depthData = depthMap.dataSync();
          const width = depthCanvas.width;
          const height = depthCanvas.height;

          // Подготовка пикселей для отрисовки
          const imageData = depthCtx.createImageData(width, height);
          for (let i = 0; i < depthData.length; i++) {
            const depthValue = Math.floor((1 - depthData[i]) * 255);
            imageData.data[i * 4] = depthValue; // Red
            imageData.data[i * 4 + 1] = depthValue; // Green
            imageData.data[i * 4 + 2] = depthValue; // Blue
            imageData.data[i * 4 + 3] = 150; // Alpha (прозрачность)
          }
          depthCtx.putImageData(imageData, 0, 0);
        }

        // Продолжаем обработку
        requestAnimationFrame(processVideo);
      }

      // Запуск приложения
      startCamera().catch((err) =>
        console.error("Error accessing camera:", err),
      );
      document.body.innerHTML += '<button id="toggleButton" onclick="toggleDepthMap()">Показать карту глубины</button>'
    </script>
  </body>
</html> -->

<!-- <!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>1 Depth Estimation with OpenCV.js</title>
    <script async src="https://cdn.jsdelivr.net/npm/opencv.js" onload="onOpenCvReady();" type="text/javascript"></script>
  </head>
  <body>
    <h1>Depth Estimation from Camera Stream</h1>
    <video id="video" width="640" height="480" autoplay></video>
    <canvas id="depthCanvas" width="640" height="480"></canvas>

    <script>
      let videoElement;
      let canvasElement;
      let canvasContext;
      let mat;
      let thresholdMat;

      // Функция, которая будет вызвана, когда OpenCV.js загрузится
      function onOpenCvReady() {
        if (cv && cv.getBuildInformation) {
          console.log("OpenCV.js загружен и готов к использованию.");
        } else {
          console.error("OpenCV.js не загружен или не готов.");
          return;
        }

        videoElement = document.getElementById("video");
        canvasElement = document.getElementById("depthCanvas");
        canvasContext = canvasElement.getContext("2d");

        // Запрашиваем доступ к камере
        navigator.mediaDevices
          .getUserMedia({ video: true })
          .then((stream) => {
            videoElement.srcObject = stream;
            videoElement.play();
          })
          .catch((err) => {
            console.error("Ошибка доступа к камере", err);
            alert(
              "Не удается получить доступ к камере. Убедитесь, что разрешили доступ.",
            );
          });

        // Настроим интервал для обработки видеопотока
        setInterval(processVideo, 100); // Обработка каждые 100 мс
      }

      // Обработка видеопотока для оценки глубины
      function processVideo() {
        if (typeof cv === "undefined") {
          console.error("OpenCV.js не загружен");
          return;
        }

        // Проверяем, готов ли видеопоток
        if (videoElement.readyState === videoElement.HAVE_ENOUGH_DATA) {
          // Создание Mat из видеопотока
          mat = cv.imread(videoElement);

          // Конвертация в градации серого (для приблизительной оценки глубины)
          let gray = new cv.Mat();
          cv.cvtColor(mat, gray, cv.COLOR_RGBA2GRAY);

          // Применение фильтра Гаусса для сглаживания
          let depthMap = new cv.Mat();
          cv.GaussianBlur(gray, depthMap, new cv.Size(5, 5), 1.5, 1.5);

          // Применение пороговой обработки
          thresholdMat = new cv.Mat();
          cv.threshold(depthMap, thresholdMat, 100, 255, cv.THRESH_BINARY);

          // Отображение результата на канвасе
          cv.imshow("depthCanvas", thresholdMat);

          // Очистка ресурсов
          mat.delete();
          gray.delete();
          depthMap.delete();
          thresholdMat.delete();
        }
      }
    </script>
  </body>
</html> -->
// @config WEBGPU_DISABLED
import * as pc from 'playcanvas';

const canvas = /** @type {HTMLCanvasElement} */ (document.getElementById('application-canvas'));
window.focus();

/**
 * @param {string} msg - The message.
 */
const message = function (msg) {
    /** @type {HTMLDivElement} */
    let el = document.querySelector('.message');
    if (!el) {
        el = document.createElement('div');
        el.classList.add('message');
        el.style.position = 'absolute';
        el.style.bottom = '96px';
        el.style.right = '0';
        el.style.padding = '8px 16px';
        el.style.fontFamily = 'Helvetica, Arial, sans-serif';
        el.style.color = '#fff';
        el.style.backgroundColor = 'rgba(0, 0, 0, 0.5)';
        document.body.append(el);
    }
    el.textContent = msg;
};

const app = new pc.Application(canvas, {
    mouse: new pc.Mouse(canvas),
    touch: new pc.TouchDevice(canvas),
    keyboard: new pc.Keyboard(window),
    graphicsDeviceOptions: { alpha: true }
});

app.setCanvasFillMode(pc.FILLMODE_FILL_WINDOW);
app.setCanvasResolution(pc.RESOLUTION_AUTO);

// Ensure canvas is resized when window changes size
const resize = () => app.resizeCanvas();
window.addEventListener('resize', resize);
app.on('destroy', () => {
    window.removeEventListener('resize', resize);
});

// use device pixel ratio
app.graphicsDevice.maxPixelRatio = window.devicePixelRatio;

app.start();

// create camera
const camera = new pc.Entity();
camera.addComponent('camera', {
    clearColor: new pc.Color(0, 0, 0, 0),
    farClip: 10000
});
app.root.addChild(camera);

let shaderUpdated = false;
let shaderDepthArray = null;
let shaderDepthFloat = null;

const vertShader = /* glsl */ `
    attribute vec3 aPosition;
    uniform mat4 matrix_model;
    uniform mat4 matrix_viewProjection;
    void main(void) {
        gl_Position = matrix_viewProjection * matrix_model * vec4(aPosition, 1.0);
    }`;

const fragShader = /* glsl */ `
    uniform vec4 uScreenSize;
    uniform mat4 matrix_depth_uv;
    uniform float depth_raw_to_meters;

    #ifdef XRDEPTH_ARRAY
        uniform int view_index;
        uniform highp sampler2DArray depthMap;
    #else
        uniform sampler2D depthMap;
    #endif

    void main (void) {
        vec2 uvScreen = gl_FragCoord.xy * uScreenSize.zw;

        // use texture array for multi-view
        #ifdef XRDEPTH_ARRAY
            uvScreen = uvScreen * vec2(2.0, 1.0) - vec2(view_index, 0.0);
            vec3 uv = vec3((matrix_depth_uv * vec4(uvScreen.xy, 0.0, 1.0)).xy, view_index);
        #else
            vec2 uv = (matrix_depth_uv * vec4(uvScreen.x, 1.0 - uvScreen.y, 0.0, 1.0)).xy;
        #endif

        #ifdef XRDEPTH_FLOAT
            float depth = texture2D(depthMap, uv).r;
        #else
            // unpack from AlphaLuminance
            vec2 packedDepth = texture2D(depthMap, uv).ra;
            float depth = dot(packedDepth, vec2(255.0, 256.0 * 255.0));
        #endif

        depth *= depth_raw_to_meters;

        gl_FragColor = vec4(depth, depth, depth, 1.0);
    }`;

const materialDepth = new pc.ShaderMaterial();

/**
 * @param {boolean} array - If the depth information uses array texture.
 * @param {boolean} float - If the depth information uses F32R texture.
 */
const updateShader = (array, float) => {
    if (shaderDepthArray === array && shaderDepthFloat === float) return;

    shaderDepthArray = array;
    shaderDepthFloat = float;

    const key = `textureDepthSensing_${array}${float}`;

    if (shaderDepthArray) materialDepth.setDefine('XRDEPTH_ARRAY', true);
    if (shaderDepthFloat) materialDepth.setDefine('XRDEPTH_FLOAT', true);

    materialDepth.shaderDesc = {
        uniqueName: key,
        vertexCode: vertShader,
        fragmentCode: fragShader,
        attributes: {
            aPosition: pc.SEMANTIC_POSITION,
            aUv0: pc.SEMANTIC_TEXCOORD0
        }
    };

    materialDepth.update();
};

updateShader(false, false);

const plane = new pc.Entity();
plane.addComponent('render', {
    type: 'plane'
});
plane.render.material = materialDepth;
plane.render.meshInstances[0].cull = false;
plane.setLocalPosition(0, 0, -1);
plane.setLocalEulerAngles(90, 0, 0);
plane.enabled = false;
camera.addChild(plane);

if (app.xr.supported) {
    const activate = function () {
        if (app.xr.isAvailable(pc.XRTYPE_AR)) {
            camera.camera.startXr(pc.XRTYPE_AR, pc.XRSPACE_LOCALFLOOR, {
                depthSensing: {
                    // request access to camera depth
                    usagePreference: pc.XRDEPTHSENSINGUSAGE_GPU,
                    dataFormatPreference: pc.XRDEPTHSENSINGFORMAT_F32
                },
                callback: function (err) {
                    if (err) message(`WebXR Immersive AR failed to start: ${err.message}`);
                }
            });
        } else {
            message('Immersive AR is not available');
        }
    };

    app.mouse.on('mousedown', () => {
        if (!app.xr.active) activate();
    });

    if (app.touch) {
        app.touch.on('touchend', (evt) => {
            if (!app.xr.active) {
                // if not in VR, activate
                activate();
            } else {
                // otherwise reset camera
                camera.camera.endXr();
            }

            evt.event.preventDefault();
            evt.event.stopPropagation();
        });
    }

    // end session by keyboard ESC
    app.keyboard.on('keydown', (evt) => {
        if (evt.key === pc.KEY_ESCAPE && app.xr.active) {
            app.xr.end();
        }
    });

    app.xr.on('start', () => {
        message('Immersive AR session has started');
        console.log('depth gpu optimized', app.xr.views.depthGpuOptimized);
        console.log('depth texture format', app.xr.views.depthPixelFormat);
    });
    app.xr.on('end', () => {
        shaderUpdated = false;
        message('Immersive AR session has ended');
        plane.enabled = false;
    });
    app.xr.on(`available:${pc.XRTYPE_AR}`, (available) => {
        if (available) {
            if (!app.xr.views.supportedDepth) {
                message('AR Camera Depth is not supported');
            } else {
                message('Touch screen to start AR session');
            }
        } else {
            message('Immersive AR is not available');
        }
    });

    app.on('update', () => {
        // if camera depth is available
        if (app.xr.views.availableDepth) {
            if (!shaderUpdated && app.xr.active) {
                shaderUpdated = true;
                updateShader(app.xr.views.list.length > 1, app.xr.views.depthPixelFormat !== pc.PIXELFORMAT_LA8);
            }

            const view = app.xr.views.list?.[0];
            if (view && view.textureDepth) {
                materialDepth.setParameter('depthMap', view.textureDepth);
                materialDepth.setParameter('matrix_depth_uv', view.depthUvMatrix.data);
                materialDepth.setParameter('depth_raw_to_meters', view.depthValueToMeters);
                plane.enabled = true;
            } else {
                plane.enabled = false;
            }
        }
    });

    if (!app.xr.isAvailable(pc.XRTYPE_AR)) {
        message('Immersive AR is not available');
    } else if (!app.xr.views.supportedDepth) {
        message('AR Camera Depth is not supported');
    } else {
        message('Touch screen to start AR session');
    }
} else {
    message('WebXR is not supported');
}

export { app };