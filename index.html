<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AR Sphere without Markers</title>

    <!-- Подключаем A-Frame -->
    <script src="https://aframe.io/releases/1.2.0/aframe.min.js"></script>

    <!-- Подключаем AR.js с поддержкой WebXR -->
    <script src="https://cdn.rawgit.com/jeromeetienne/AR.js/2.1.4/aframe/build/aframe-ar.js"></script>
  </head>
  <body style="margin: 0; overflow: hidden;">
    <!-- A-Frame сцена для AR -->
    <a-scene>
        <a-entity camera></a-entity>
        <a-entity id="heatmap" visible="false"></a-entity>
        <button onclick="toggleHeatmap()">Toggle Heatmap</button>
      </a-scene>
      
      <canvas id="heatmapCanvas" style="position: absolute; top: 0; left: 0; pointer-events: none;"></canvas>
      
      <script>
        let heatmapVisible = false;
        const canvas = document.getElementById('heatmapCanvas');
        const ctx = canvas.getContext('2d');
        
        function toggleHeatmap() {
          heatmapVisible = !heatmapVisible;
          document.getElementById('heatmap').setAttribute('visible', heatmapVisible);
          
          if (heatmapVisible) {
            startDepthAnalysis();
          } else {
            stopDepthAnalysis();
          }
        }
      
        function startDepthAnalysis() {
          // Пример: Инициализация камеры и захват данных
          navigator.mediaDevices.getUserMedia({ video: { facingMode: 'environment' } })
            .then(stream => {
              const video = document.createElement('video');
              video.srcObject = stream;
              video.play();
              // Обновляем размер канваса
              canvas.width = window.innerWidth;
              canvas.height = window.innerHeight;
              drawHeatmap(video);
            });
        }
      
        function drawHeatmap(video) {
  ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
  
  // Пример: Логика получения данных о глубине
  // В реальном приложении замените этот код на фактическое получение данных о глубине
  const depthData = getDepthData(canvas.width, canvas.height);

  // Обработка пикселей для отображения тепловой карты
  const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
  const data = imageData.data;

  for (let i = 0; i < data.length; i += 4) {
    const depthValue = depthData[i / 4]; // Получаем значение глубины для каждого пикселя

    // Преобразование значения глубины в цвет
    const color = depthToColor(depthValue);
    
    data[i] = color.r;     // Red
    data[i + 1] = color.g; // Green
    data[i + 2] = color.b; // Blue
    data[i + 3] = 255;     // Alpha
  }

  ctx.putImageData(imageData, 0, 0); // Обновляем канвас с новой тепловой картой

  requestAnimationFrame(() => drawHeatmap(video)); // Продолжаем обновлять
}

// Пример функции для получения данных о глубине
function getDepthData(width, height) {
  const depthData = new Array(width * height);

  for (let i = 0; i < depthData.length; i++) {
    // Здесь вы можете заменить случайное значение на реальные данные о глубине
    depthData[i] = Math.random() * 100; // Пример: значения от 0 до 100
  }

  return depthData;
}

// Функция преобразования глубины в цвет
function depthToColor(depth) {
  const maxDepth = 100; // Максимальное расстояние для тепловой карты
  const normalizedDepth = Math.min(depth / maxDepth, 1); // Нормализация

  // Пример: преобразование в цвет с помощью градиента
  const r = Math.floor(normalizedDepth * 255);
  const g = 0;
  const b = Math.floor((1 - normalizedDepth) * 255);

  return { r, g, b };
}

      
        function stopDepthAnalysis() {
  // Остановка потока видео
  if (video && video.srcObject) {
    const stream = video.srcObject;
    const tracks = stream.getTracks();
    
    tracks.forEach(track => track.stop()); // Останавливаем все треки видео
    video.srcObject = null;
  }

  // Очистка канваса
  ctx.clearRect(0, 0, canvas.width, canvas.height);
}

      </script>
      
  </body>
</html>
