<!-- <!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Depth Map on Video</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/depth-estimation@2.0.0/dist/index.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js"></script>
    <style>
      body {
        margin: 0;
        display: flex;
        flex-direction: column;
        align-items: center;
        justify-content: center;
        background-color: black;
      }
      #video,
      #depthCanvas {
        position: absolute;
        top: 0;
        left: 0;
        width: 100%;
        height: auto;
      }
    </style>
  </head>
  <body>
    <video id="video" autoplay playsinline></video>
    <canvas id="depthCanvas"></canvas>

    <script>
      const video = document.getElementById("video");
      const depthCanvas = document.getElementById("depthCanvas");
      const depthCtx = depthCanvas.getContext("2d");
      let depthEstimator;
      async function toggleDepthMap() {
        if (depthCanvas.style.display === "none") {
          document.getElementById("toggleButton").innerText =
            "Скрыть карту глубины";
          depthCanvas.style.display = "block";
          if (!video) await startCamera();

          // Проверяем, загружена ли библиотека
          if (typeof depthEstimation !== "undefined") {
            if (!depthEstimator) await initializeDepthModel();
            updateDepthMap();
          } else {
            console.error(
              "depthEstimation не найден. Убедитесь, что библиотека правильно загружена.",
            );
          }
        } else {
          document.getElementById("toggleButton").innerText =
            "Показать карту глубины";
          depthCanvas.style.display = "none";
        }
      }
      // Запуск камеры
      async function startCamera() {
        const stream = await navigator.mediaDevices.getUserMedia({
          video: { facingMode: "environment" },
        });
        video.srcObject = stream;

        // Ожидаем загрузки видео
        video.onloadedmetadata = () => {
          video.play();
          depthCanvas.width = video.videoWidth;
          depthCanvas.height = video.videoHeight;
          initializeDepthModel();
        };
      }

      // Инициализация модели TensorFlow
      async function initializeDepthModel() {
        depthEstimator = await depthEstimation.createEstimator(
          depthEstimation.SupportedModels.COCODepthEstimation,
        );
        console.log("Depth model loaded");
        processVideo();
      }

      // Обработка видео и отрисовка карты глубины
      async function processVideo() {
        if (depthEstimator && video.readyState >= video.HAVE_ENOUGH_DATA) {
          // Генерация карты глубины
          const depthMap = await depthEstimator.estimateDepth(video);
          const depthData = depthMap.dataSync();
          const width = depthCanvas.width;
          const height = depthCanvas.height;

          // Подготовка пикселей для отрисовки
          const imageData = depthCtx.createImageData(width, height);
          for (let i = 0; i < depthData.length; i++) {
            const depthValue = Math.floor((1 - depthData[i]) * 255);
            imageData.data[i * 4] = depthValue; // Red
            imageData.data[i * 4 + 1] = depthValue; // Green
            imageData.data[i * 4 + 2] = depthValue; // Blue
            imageData.data[i * 4 + 3] = 150; // Alpha (прозрачность)
          }
          depthCtx.putImageData(imageData, 0, 0);
        }

        // Продолжаем обработку
        requestAnimationFrame(processVideo);
      }

      // Запуск приложения
      startCamera().catch((err) =>
        console.error("Error accessing camera:", err),
      );
      document.body.innerHTML += '<button id="toggleButton" onclick="toggleDepthMap()">Показать карту глубины</button>'
    </script>
  </body>
</html> -->

<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Depth Estimation with OpenCV.js</title>
    <script>
      function onOpenCvReady() {
        console.log("OpenCV Ready", cv);
      }
    </script>
    <script
      async
      src="https://cdn.jsdelivr.net/npm/opencv.js"
      onload="onOpenCvReady();"
      type="text/javascript"
    ></script>
  </head>
  <body>
    <h1>Depth Estimation from Camera Stream111</h1>
    <video id="video" width="640" height="480" autoplay></video>
    <canvas id="depthCanvas" width="640" height="480"></canvas>

    <script>
      let videoElement;
      let canvasElement;
      let canvasContext;

      // Функция, которая будет вызвана, когда OpenCV.js загрузится
      function onOpenCvReady() {
        if (cv && cv.getBuildInformation) {
          console.log("OpenCV.js загружен и готов к использованию.");
        } else {
          console.error("OpenCV.js не загружен или не готов.");
          return;
        }

        videoElement = document.getElementById("video");
        canvasElement = document.getElementById("depthCanvas");
        canvasContext = canvasElement.getContext("2d");

        // Запрашиваем доступ к камере
        navigator.mediaDevices
          .getUserMedia({ video: true })
          .then((stream) => {
            videoElement.srcObject = stream;
            videoElement.play();
          })
          .catch((err) => {
            console.error("Ошибка доступа к камере", err);
            alert(
              "Не удается получить доступ к камере. Убедитесь, что разрешили доступ.",
            );
          });

        // Настроим интервал для обработки видеопотока
        setInterval(processVideo, 100); // Обработка каждые 100 мс
      }

      // Обработка видеопотока для оценки глубины
      function processVideo() {
        if (typeof cv === "undefined") {
          console.error("OpenCV.js не загружен");
          return;
        }

        // Проверяем, готов ли видеопоток
        if (videoElement.readyState === videoElement.HAVE_ENOUGH_DATA) {
          // Создание Mat из видеопотока
          let mat = cv.imread(videoElement);

          // Конвертация в градации серого (для приблизительной оценки глубины)
          let gray = new cv.Mat();
          cv.cvtColor(mat, gray, cv.COLOR_RGBA2GRAY);

          // Применение фильтра Гаусса для сглаживания
          let depthMap = new cv.Mat();
          cv.GaussianBlur(gray, depthMap, new cv.Size(5, 5), 1.5, 1.5);

          // Применение алгоритма Канни для выделения контуров
          cv.Canny(depthMap, depthMap, 50, 100);

          // Отображение результата на канвасе
          cv.imshow("depthCanvas", depthMap);

          // Очистка ресурсов
          mat.delete();
          gray.delete();
          depthMap.delete();
        }
      }
    </script>
  </body>
</html>
