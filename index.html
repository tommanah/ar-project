<!-- <!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>AR Depth Map</title>
    <script src="https://aframe.io/releases/1.2.0/aframe.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/depth-estimation@latest/index.js"></script>
    <style>
      #depthCanvas {
        position: fixed;
        top: 100px;
        left: 10px;
        width: 320px;
        height: 240px;
        z-index: 1000;
        display: none;
      }
      #toggleButton {
        position: fixed;
        top: 10px;
        left: 10px;
        z-index: 1001;
        padding: 10px;
        background-color: #007bff;
        color: white;
        border: none;
        cursor: pointer;
      }
    </style>
  </head>
  <body style="margin: 0">
    <button id="toggleButton" onclick="toggleDepthMap()">Показать карту глубины</button>
    <canvas id="depthCanvas"></canvas>

    <a-scene embedded arjs="sourceType: webcam;">
      <a-entity camera></a-entity>
    </a-scene>

    <script>
      let depthEstimator;
      let depthCanvas = document.getElementById("depthCanvas");
      let depthContext = depthCanvas.getContext("2d");
      let video;

      async function initializeDepthModel() {
        const model = depthEstimation.SupportedModels.COCODepthEstimation;
        depthEstimator = await depthEstimation.createEstimator(model);
      }

      async function startCamera() {
        video = document.createElement("video");
        const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: "environment" } });
        video.srcObject = stream;
        await video.play();
      }

      async function updateDepthMap() {
        if (depthEstimator && video.readyState === video.HAVE_ENOUGH_DATA) {
          const depthMap = await depthEstimator.estimateDepth(video);
          const depthData = depthMap.dataSync();
          const width = 320, height = 240;
          depthCanvas.width = width;
          depthCanvas.height = height;

          const imageData = depthContext.createImageData(width, height);
          for (let i = 0; i < depthData.length; i++) {
            const depthValue = Math.floor((1 - depthData[i]) * 255);
            imageData.data[i * 4] = depthValue;         // Red
            imageData.data[i * 4 + 1] = 0;             // Green
            imageData.data[i * 4 + 2] = 255 - depthValue; // Blue
            imageData.data[i * 4 + 3] = 255;           // Alpha
          }
          depthContext.putImageData(imageData, 0, 0);
        }
        requestAnimationFrame(updateDepthMap);
      }

      async function toggleDepthMap() {
        if (depthCanvas.style.display === "none") {
          document.getElementById("toggleButton").innerText = "Скрыть карту глубины";
          depthCanvas.style.display = "block";
          if (!video) await startCamera();
          if (!depthEstimator) await initializeDepthModel();
          updateDepthMap();
        } else {
          document.getElementById("toggleButton").innerText = "Показать карту глубины";
          depthCanvas.style.display = "none";
        }
      }
    </script>
  </body>
</html> -->
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Depth Estimation with Camera</title>
  <script src="https://cdn.jsdelivr.net/npm/@huggingface/transformers@4.17.0/dist/transformers.js"></script>
</head>
<body>
  <h1>Depth Estimation from Camera Stream</h1>
  <video id="video" width="640" height="480" autoplay></video>
  <canvas id="canvas" width="640" height="480"></canvas>
  
  <script>
    // Initialize camera stream
    async function initCamera() {
      const video = document.getElementById('video');
      const stream = await navigator.mediaDevices.getUserMedia({
        video: true
      });
      video.srcObject = stream;
    }

    // Load the pre-trained depth estimation model
    async function loadModel() {
      const model = await window.Transformers.load("huggingface/transformers.js", "depth-estimation");
      return model;
    }

    // Process the video frame and predict depth
    async function predictDepth(model, video) {
      const canvas = document.getElementById('canvas');
      const ctx = canvas.getContext('2d');
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

      const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
      const result = await model.estimateDepth(imageData);
      drawDepthMap(result);
    }

    // Draw the depth map on the canvas
    function drawDepthMap(depthMap) {
      const canvas = document.getElementById('canvas');
      const ctx = canvas.getContext('2d');
      const imageData = ctx.createImageData(canvas.width, canvas.height);
      
      for (let i = 0; i < depthMap.length; i++) {
        const depthValue = depthMap[i];
        imageData.data[i * 4 + 0] = depthValue; // Red channel (depth visualization)
        imageData.data[i * 4 + 1] = depthValue;
        imageData.data[i * 4 + 2] = depthValue;
        imageData.data[i * 4 + 3] = 255; // Alpha channel
      }

      ctx.putImageData(imageData, 0, 0);
    }

    // Initialize everything
    async function start() {
      await initCamera();
      const model = await loadModel();
      const video = document.getElementById('video');
      
      setInterval(() => {
        predictDepth(model, video);
      }, 100); // Predict every 100ms
    }

    start();
  </script>
</body>
</html>
