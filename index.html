<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Карта глубины</title>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/110/three.min.js"></script>
  <style>
    body {
      margin: 0;
      overflow: hidden;
    }
    canvas {
      display: block;
    }
  </style>
</head>
<body>
  <script>
    // Доступ к видеопотоку с телефона
    async function getCameraStream() {
      return navigator.mediaDevices.getUserMedia({
        video: { width: 640, height: 480 },
        audio: false,
      });
    }

    // Инициализация видео-текстуры
    async function setupVideoTexture() {
      const stream = await getCameraStream();

      // Создаем видеоэлемент
      const video = document.createElement('video');
      video.srcObject = stream;
      video.play();

      // Создаем текстуру для WebGL
      const texture = new THREE.VideoTexture(video);
      return texture;
    }

    // Инициализация сцены
    async function init() {
      const videoTexture = await setupVideoTexture();

      const scene = new THREE.Scene();
      const camera = new THREE.OrthographicCamera(-1, 1, 1, -1, 0.1, 10);
      camera.position.z = 1;

      const renderer = new THREE.WebGLRenderer();
      renderer.setSize(window.innerWidth, window.innerHeight);
      document.body.appendChild(renderer.domElement);

      // Материал для отображения карты глубины
      const depthMaterial = new THREE.ShaderMaterial({
        uniforms: {
          videoTexture: { value: videoTexture },
          offset: { value: 0.01 }, // Смещение для правого "глаза"
        },
        vertexShader: `
          varying vec2 vUv;
          void main() {
            vUv = uv;
            gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
          }
        `,
        fragmentShader: `
          varying vec2 vUv;
          uniform sampler2D videoTexture;
          uniform float offset;

          void main() {
            // Эмуляция левого и правого изображения с использованием смещения
            vec2 leftUV = vUv;
            vec2 rightUV = vUv + vec2(offset, 0.0);

            vec4 leftColor = texture2D(videoTexture, leftUV);
            vec4 rightColor = texture2D(videoTexture, rightUV);

            // Расчет диспаритета (разницы между левым и правым изображением)
            float disparity = abs(leftColor.r - rightColor.r);

            // Отображение карты глубины
            gl_FragColor = vec4(vec3(disparity), 1.0);
          }
        `,
      });

      // Плоскость для отображения
      const plane = new THREE.Mesh(new THREE.PlaneGeometry(2, 2), depthMaterial);
      scene.add(plane);

      // Рендеринг
      function animate() {
        requestAnimationFrame(animate);
        renderer.render(scene, camera);
      }
      animate();
    }

    // Запуск
    init().catch(console.error);
  </script>
</body>
</html>
